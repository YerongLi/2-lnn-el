{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000],\n",
       "        [0.4000],\n",
       "        [0.1000]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacc_features = torch.Tensor([[0.5], [0.4], [0.1]])\n",
    "threshold = 0.2\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000],\n",
       "        [0.4000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul( torch.floor( ( torch.sign(jacc_features - threshold)+1.0) / 2.0 ), jacc_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([[-2.4877e-41],\n",
    "        [ 1.1065e-09],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.7509e-21],\n",
    "        [ 0.0000e+00],\n",
    "        [ 0.0000e+00],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.9690e-06],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.6707e-15],\n",
    "        [ 0.0000e+00],\n",
    "        [ 2.6540e-25],\n",
    "        [-1.1854e-39],\n",
    "        [ 3.9624e-06],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.4878e-17],\n",
    "        [-1.0118e-14],\n",
    "        [ 3.9206e-14],\n",
    "        [ 0.0000e+00],\n",
    "        [ 2.5238e-22],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.2006e-03],\n",
    "        [-2.9248e-16],\n",
    "        [ 1.3972e-06],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.5014e-17],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.6665e-23],\n",
    "        [-1.4952e-17],\n",
    "        [ 1.5208e-06],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.0632e-06],\n",
    "        [ 0.0000e+00],\n",
    "        [ 2.8194e-07],\n",
    "        [ 0.0000e+00],\n",
    "        [ 3.6251e-22],\n",
    "        [-4.6488e-04],\n",
    "        [ 1.2210e-06],\n",
    "        [ 0.0000e+00],\n",
    "        [ 8.9633e-32],\n",
    "        [ 0.0000e+00],\n",
    "        [ 3.6415e-17],\n",
    "        [-4.1997e-19],\n",
    "        [ 8.0116e-38],\n",
    "        [ 0.0000e+00],\n",
    "        [ 5.2410e-07],\n",
    "        [ 0.0000e+00],\n",
    "        [ 4.1708e-06],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.0778e-30],\n",
    "        [ 0.0000e+00],\n",
    "        [ 3.5776e-31],\n",
    "        [ 0.0000e+00],\n",
    "        [ 2.6749e-03],\n",
    "        [ 0.0000e+00],\n",
    "        [ 6.6734e-19],\n",
    "        [-2.9273e-28],\n",
    "        [ 0.0000e+00],\n",
    "        [ 0.0000e+00],\n",
    "        [ 0.0000e+00],\n",
    "        [ 0.0000e+00],\n",
    "        [ 0.0000e+00],\n",
    "        [ 0.0000e+00],\n",
    "        [ 1.5475e-25]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['purename', 'False', 0.85, 0.8015, 0.7569, 0.7786]\n",
      "['context', 'False', 0.85, 0.7887, 0.7442, 0.7658]\n",
      "['complex', 'False', 0.85, 0.8079, 0.7633, 0.7849]\n",
      "['purename', 'False', 0.9, 0.7983, 0.7537, 0.7754]\n",
      "['context', 'False', 0.9, 0.7887, 0.7442, 0.7658]\n",
      "['complex', 'False', 0.9, 0.7856, 0.741, 0.7626]\n",
      "['purename', 'False', 0.95, 0.7856, 0.741, 0.7626]\n",
      "['context', 'False', 0.95, 0.7665, 0.7282, 0.7469]\n",
      "['complex', 'False', 0.95, 0.2197, 0.1911, 0.2044]\n",
      "[['purename', 'False', 0.85, 0.8015, 0.7569, 0.7786], ['context', 'False', 0.85, 0.7887, 0.7442, 0.7658], ['complex', 'False', 0.85, 0.8079, 0.7633, 0.7849], ['purename', 'False', 0.9, 0.7983, 0.7537, 0.7754], ['context', 'False', 0.9, 0.7887, 0.7442, 0.7658], ['complex', 'False', 0.9, 0.7856, 0.741, 0.7626], ['purename', 'False', 0.95, 0.7856, 0.741, 0.7626], ['context', 'False', 0.95, 0.7665, 0.7282, 0.7469], ['complex', 'False', 0.95, 0.2197, 0.1911, 0.2044]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"output.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "rows = []\n",
    "columns = ['model', 'binary', 'alpha', 'precision', 'recall', 'f1']\n",
    "for line in lines:\n",
    "    items = line.split('; ')\n",
    "    items = [item.split('=')[-1].strip() for item in items]\n",
    "    for i in range(2, 6):\n",
    "        items[i] = float(items[i])\n",
    "    print(items)\n",
    "    rows.append(items)\n",
    "\n",
    "print(rows)\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## form tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the wife of U.S. president Lincoln?</td>\n",
       "      <td>[[('http://dbpedia.org/resource/United_States'...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many people live in the capital of Australia?</td>\n",
       "      <td>[[('http://dbpedia.org/resource/Australia', 1....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many theories did Albert Einstein come up ...</td>\n",
       "      <td>[[('http://dbpedia.org/resource/Albert_Einstei...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who composed the soundtrack for Cameron's Tita...</td>\n",
       "      <td>[[('http://dbpedia.org/resource/David_Cameron'...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Give me the runtime of Toy Story.</td>\n",
       "      <td>[[('http://dbpedia.org/resource/Toy_Story_3', ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0        Who was the wife of U.S. president Lincoln?   \n",
       "1  How many people live in the capital of Australia?   \n",
       "2  How many theories did Albert Einstein come up ...   \n",
       "3  Who composed the soundtrack for Cameron's Tita...   \n",
       "4                  Give me the runtime of Toy Story.   \n",
       "\n",
       "                                            Entities Classes  \n",
       "0  [[('http://dbpedia.org/resource/United_States'...      []  \n",
       "1  [[('http://dbpedia.org/resource/Australia', 1....      []  \n",
       "2  [[('http://dbpedia.org/resource/Albert_Einstei...      []  \n",
       "3  [[('http://dbpedia.org/resource/David_Cameron'...      []  \n",
       "4  [[('http://dbpedia.org/resource/Toy_Story_3', ...      []  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"output/complex_nway_alpha085.csv\")\n",
    "df1 = df1[['Question', 'Entities', 'Classes']]\n",
    "print(df1.shape)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = pd.read_csv(\"data/missing.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which species does an elephant belong?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In which ancient empire could you pay with coc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which city has the most inhabitants?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is in a chocolate chip cookie?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which holidays are celebrated around the world?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question Entities Classes\n",
       "0             Which species does an elephant belong?       []      []\n",
       "1  In which ancient empire could you pay with coc...       []      []\n",
       "2               Which city has the most inhabitants?       []      []\n",
       "3                What is in a chocolate chip cookie?       []      []\n",
       "4    Which holidays are celebrated around the world?       []      []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_missing.columns = ['Unnamed:0', 'Question', 'Entities', 'Classes']\n",
    "df_missing = df_missing[['Question', 'Entities', 'Classes']]\n",
    "df_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the wife of U.S. president Lincoln?</td>\n",
       "      <td>[[('http://dbpedia.org/resource/United_States'...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many people live in the capital of Australia?</td>\n",
       "      <td>[[('http://dbpedia.org/resource/Australia', 1....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many theories did Albert Einstein come up ...</td>\n",
       "      <td>[[('http://dbpedia.org/resource/Albert_Einstei...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who composed the soundtrack for Cameron's Tita...</td>\n",
       "      <td>[[('http://dbpedia.org/resource/David_Cameron'...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Give me the runtime of Toy Story.</td>\n",
       "      <td>[[('http://dbpedia.org/resource/Toy_Story', 1....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>List all episodes of the first season of the H...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Which city has the least inhabitants?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Is proinsulin a protein?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Which city has the oldest running metro?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>What is the bridge with the longest span?</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Question  \\\n",
       "0          Who was the wife of U.S. president Lincoln?   \n",
       "1    How many people live in the capital of Australia?   \n",
       "2    How many theories did Albert Einstein come up ...   \n",
       "3    Who composed the soundtrack for Cameron's Tita...   \n",
       "4                    Give me the runtime of Toy Story.   \n",
       "..                                                 ...   \n",
       "152  List all episodes of the first season of the H...   \n",
       "153              Which city has the least inhabitants?   \n",
       "154                           Is proinsulin a protein?   \n",
       "155           Which city has the oldest running metro?   \n",
       "156          What is the bridge with the longest span?   \n",
       "\n",
       "                                              Entities Classes  \n",
       "0    [[('http://dbpedia.org/resource/United_States'...      []  \n",
       "1    [[('http://dbpedia.org/resource/Australia', 1....      []  \n",
       "2    [[('http://dbpedia.org/resource/Albert_Einstei...      []  \n",
       "3    [[('http://dbpedia.org/resource/David_Cameron'...      []  \n",
       "4    [[('http://dbpedia.org/resource/Toy_Story', 1....      []  \n",
       "..                                                 ...     ...  \n",
       "152                                                 []      []  \n",
       "153                                                 []      []  \n",
       "154                                                 []      []  \n",
       "155                                                 []      []  \n",
       "156                                                 []      []  \n",
       "\n",
       "[157 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df1, df_missing], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from el_evaluation import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"main training script for training lnn entity linking models\")\n",
    "parser.add_argument(\"--train_data\", type=str, default=\"./data/train.csv\", help=\"train csv\")\n",
    "parser.add_argument(\"--test_data\", type=str, default=\"./data/test.csv\", help=\"test csv\")\n",
    "parser.add_argument(\"--checkpoint_name\", type=str, default=\"checkpoint/best_model.pt\", help=\"checkpoint path\")\n",
    "parser.add_argument(\"--output_file_name\", type=str, default=\"output/purename_nway_alpha09.txt\", help=\"checkpoint path\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"purename\", help=\"which model we choose\")\n",
    "# args for dividing the corpus\n",
    "parser.add_argument('--alpha', type=float, default=0.9, help='alpha for LNN')\n",
    "parser.add_argument('--num_epoch', type=int, default=100, help='training epochs for LNN')\n",
    "parser.add_argument(\"--use_binary\", action=\"store_true\", help=\"default is to use binary`, otherwise use stem\")\n",
    "parser.add_argument(\"-f\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.use_binary:\n",
    "    from RuleLNN_binary import *\n",
    "else:\n",
    "    from RuleLNN_nway_theta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [2., 3., 1.]])\n",
      "tensor([[0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 1, 1], [2, 3, 1]])\n",
    "print(a)\n",
    "b = torch.Tensor([[0], [0]])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 0.],\n",
       "        [2., 3., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a,b], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.5000], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = torch.nn.Parameter(torch.Tensor([0.5]))\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [ True,  True, False]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/3 >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContextLNN(\n",
       "  (sim_disjunction_or): or_lukasiewicz(\n",
       "    (AND): and_lukasiewicz(\n",
       "      (cdd): cdd_lnn()\n",
       "    )\n",
       "  )\n",
       "  (predicate_and): and_lukasiewicz(\n",
       "    (cdd): cdd_lnn()\n",
       "  )\n",
       "  (batch_norm): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (batch_norm_cat): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestModel = ContextLNN(0.85, -1, False)\n",
    "bestModel.load_state_dict(torch.load(\"checkpoint/best_model.pt\"))\n",
    "bestModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class or_sum(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO: change this\n",
    "        return torch.sum(x, 1, keepdim=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [2., 3., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.],\n",
       "        [6.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a)\n",
    "or_sum()(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.2000], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.2500], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.1117]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 1.7367, -0.3614,  0.5991,  0.3991,  0.0964,  1.1870]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[0.0428]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.6838, -2.6671, -1.8335, -1.6172]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2487, -0.1358, -0.3617,  0.2377,  1.2439,  0.7895],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.9395, -0.7981, -0.6839, -0.8211,  0.3392,  0.2754],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.8534, 0.0187, 0.2231], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.5101, -0.5262, -0.4510], requires_grad=True)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bestModel.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [[('http://dbpedia.org/resource/U.S._state', 2.122520923614502), ('http://dbpedia.org/resource/United_States', 1.9040855169296265), ('http://dbpedia.org/resource/United_States_Census_Bureau', 1.2175928354263306), ('http://dbpedia.org/resource/United_States_Navy', 1.1561580896377563), ('http://dbpedia.org/resource/Georgia_(U.S._state)', 1.1186010837554932)], [('http://dbpedia.org/resource/United_States', 6.0), ('http://dbpedia.org/resource/United_States_Navy', 3.022167205810547), ('http://dbpedia.org/resource/United_States_Army', 2.7872660160064697), ('http://dbpedia.org/resource/United_States_Senate', 2.6330716609954834), ('http://dbpedia.org/resource/United_States_Census_Bureau', 2.4424610137939453)], [('http://dbpedia.org/resource/Lincolnshire', 2.5069339275360107), ('http://dbpedia.org/resource/Abraham_Lincoln', 2.163151979446411), ('http://dbpedia.org/resource/Lincoln_City_F.C.', 2.0932846069335938), ('http://dbpedia.org/resource/Lincoln_Near-Earth_Asteroid_Research', 1.9766583442687988), ('http://dbpedia.org/resource/Lincoln,_England', 1.7709510326385498)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('http://dbpedia.org/resource/U.S._state', 2.122520923614502),\n",
       "  ('http://dbpedia.org/resource/United_States', 1.9040855169296265),\n",
       "  ('http://dbpedia.org/resource/United_States_Census_Bureau',\n",
       "   1.2175928354263306),\n",
       "  ('http://dbpedia.org/resource/United_States_Navy', 1.1561580896377563),\n",
       "  ('http://dbpedia.org/resource/Georgia_(U.S._state)', 1.1186010837554932)],\n",
       " [('http://dbpedia.org/resource/United_States', 6.0),\n",
       "  ('http://dbpedia.org/resource/United_States_Navy', 3.022167205810547),\n",
       "  ('http://dbpedia.org/resource/United_States_Army', 2.7872660160064697),\n",
       "  ('http://dbpedia.org/resource/United_States_Senate', 2.6330716609954834),\n",
       "  ('http://dbpedia.org/resource/United_States_Census_Bureau',\n",
       "   2.4424610137939453)],\n",
       " [('http://dbpedia.org/resource/Lincolnshire', 2.5069339275360107),\n",
       "  ('http://dbpedia.org/resource/Abraham_Lincoln', 2.163151979446411),\n",
       "  ('http://dbpedia.org/resource/Lincoln_City_F.C.', 2.0932846069335938),\n",
       "  ('http://dbpedia.org/resource/Lincoln_Near-Earth_Asteroid_Research',\n",
       "   1.9766583442687988),\n",
       "  ('http://dbpedia.org/resource/Lincoln,_England', 1.7709510326385498)]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[('http://dbpedia.org/resource/United_States', 5.999999999999999),\n",
       "   ('http://dbpedia.org/resource/United_States_Navy', 3.0221670864000245),\n",
       "   ('http://dbpedia.org/resource/United_States_Army', 2.787266198066909),\n",
       "   ('http://dbpedia.org/resource/United_States_Senate', 2.633071769823949),\n",
       "   ('http://dbpedia.org/resource/United_States_Census_Bureau',\n",
       "    2.44246074269411)]],\n",
       " [[('http://dbpedia.org/resource/Lincolnshire', 2.5069341912486776),\n",
       "   ('http://dbpedia.org/resource/Abraham_Lincoln', 2.1631519342356977),\n",
       "   ('http://dbpedia.org/resource/Lincoln_City_F.C.', 2.0932846530592344),\n",
       "   ('http://dbpedia.org/resource/Lincoln_Near-Earth_Asteroid_Research',\n",
       "    1.9766583104509454),\n",
       "   ('http://dbpedia.org/resource/Lincoln,_England', 1.7709509522581537)]]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold = [[[('http://dbpedia.org/resource/United_States', 5.999999999999999), ('http://dbpedia.org/resource/United_States_Navy', 3.0221670864000245), ('http://dbpedia.org/resource/United_States_Army', 2.787266198066909), ('http://dbpedia.org/resource/United_States_Senate', 2.633071769823949), ('http://dbpedia.org/resource/United_States_Census_Bureau', 2.44246074269411)]], [[('http://dbpedia.org/resource/Lincolnshire', 2.5069341912486776), ('http://dbpedia.org/resource/Abraham_Lincoln', 2.1631519342356977), ('http://dbpedia.org/resource/Lincoln_City_F.C.', 2.0932846530592344), ('http://dbpedia.org/resource/Lincoln_Near-Earth_Asteroid_Research', 1.9766583104509454), ('http://dbpedia.org/resource/Lincoln,_England', 1.7709509522581537)]]]\n",
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_val = pd.read_csv(args.train_data)\n",
    "df_test = pd.read_csv(args.test_data)\n",
    "\n",
    "# train\n",
    "features_train_val = np.array(\n",
    "    [np.fromstring(s[1:-1], dtype=np.float, sep=', ') for s in df_train_val.Features.values])\n",
    "X_train_val = torch.from_numpy(features_train_val).float()\n",
    "Y_train_val = torch.from_numpy(df_train_val.Label.values).float()\n",
    "mention_labels_train_val = df_train_val.Mention_label.values\n",
    "questions_train_val = df_train_val.Question.values\n",
    "x_train, x_val, y_train, y_val, m_labels_train, m_labels_val, ques_train, ques_val = \\\n",
    "    train_test_split(X_train_val, Y_train_val, mention_labels_train_val, questions_train_val,\n",
    "                     test_size=0.2, train_size=0.8, random_state=100)\n",
    "\n",
    "# test\n",
    "features_test = np.array([np.fromstring(s[1:-1], dtype=np.float, sep=', ') for s in df_test.Features.values])\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(df_test.Label.values).float()\n",
    "m_labels_test = df_test.Mention_label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Question</th>\n",
       "      <th>Mention_label</th>\n",
       "      <th>Features</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Who was the wife of U.S. president Lincoln?</td>\n",
       "      <td>U.S.;United States</td>\n",
       "      <td>[0.5961538553237915, 0.0, 0.15384615384615385,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Who was the wife of U.S. president Lincoln?</td>\n",
       "      <td>U.S.;National Register of Historic Places</td>\n",
       "      <td>[0.42592594027519226, 0.0, 0.02777777777777779...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Who was the wife of U.S. president Lincoln?</td>\n",
       "      <td>U.S.;United States Census Bureau</td>\n",
       "      <td>[0.5722222328186035, 0.0, 0.07407407407407407,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Who was the wife of U.S. president Lincoln?</td>\n",
       "      <td>U.S.;Hispanic (U.S. Census)</td>\n",
       "      <td>[0.6439393758773804, 0.0, 0.18181818181818177,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Who was the wife of U.S. president Lincoln?</td>\n",
       "      <td>U.S.;United States Navy</td>\n",
       "      <td>[0.5833333134651184, 0.0, 0.11111111111111116,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     Question  \\\n",
       "0           0  Who was the wife of U.S. president Lincoln?   \n",
       "1           1  Who was the wife of U.S. president Lincoln?   \n",
       "2           2  Who was the wife of U.S. president Lincoln?   \n",
       "3           3  Who was the wife of U.S. president Lincoln?   \n",
       "4           4  Who was the wife of U.S. president Lincoln?   \n",
       "\n",
       "                               Mention_label  \\\n",
       "0                         U.S.;United States   \n",
       "1  U.S.;National Register of Historic Places   \n",
       "2           U.S.;United States Census Bureau   \n",
       "3                U.S.;Hispanic (U.S. Census)   \n",
       "4                    U.S.;United States Navy   \n",
       "\n",
       "                                            Features  Label  \n",
       "0  [0.5961538553237915, 0.0, 0.15384615384615385,...      0  \n",
       "1  [0.42592594027519226, 0.0, 0.02777777777777779...      0  \n",
       "2  [0.5722222328186035, 0.0, 0.07407407407407407,...      0  \n",
       "3  [0.6439393758773804, 0.0, 0.18181818181818177,...      0  \n",
       "4  [0.5833333134651184, 0.0, 0.11111111111111116,...      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_test.Question.values))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_model(model_name, alpha):\n",
    "    if model_name == \"purename\":\n",
    "        return PureNameLNN(alpha, 2, False)\n",
    "    elif model_name == \"context\":\n",
    "        return ContextLNN(alpha, 2, False)\n",
    "    elif model_name == \"complex\":\n",
    "        return ComplexRuleLNN(alpha, 2, False)\n",
    "    else:\n",
    "        print(\"WRONG name input\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_qald_metrics(val_pred, val_y, val_m_labels, ques_val):\n",
    "    \"\"\"val_pred are 0/1 s after applying a threshold\"\"\"\n",
    "    rows = []\n",
    "    question_rows_map = defaultdict(list)\n",
    "\n",
    "    for i, pred in enumerate(val_pred):\n",
    "        pred = pred.data.tolist()[0]\n",
    "        if pred:\n",
    "            men_entity_label = '_'.join(val_m_labels[i].split(';')[-1].split())\n",
    "            question_rows_map[ques_val[i]].append(('http://dbpedia.org/resource/{}'.format(men_entity_label), 1.0))\n",
    "#             print(ques_val[i], question_rows_map[ques_val[i]])\n",
    "\n",
    "    for key, value in question_rows_map.items():\n",
    "        rows.append([key, [value]])\n",
    "\n",
    "    df_output = pd.DataFrame(rows, columns=['Question', 'Entities'])\n",
    "    df_output['Classes'] = str([])\n",
    "    df_output.head()\n",
    "    \n",
    "    # gold \n",
    "    benchmark = pd.read_csv('../../../data/gt_sparql.csv')\n",
    "    benchmark = benchmark.set_index('Question')\n",
    "    benchmark = benchmark.replace(np.nan, '', regex=True)\n",
    "    benchmark['Entities'] = benchmark['Entities'].astype(object)\n",
    "    is_qald_gt = True\n",
    "    \n",
    "    # pred \n",
    "    predictions = df_output\n",
    "    predictions = predictions.set_index('Question')\n",
    "    predictions['Entities'] = predictions['Entities']\n",
    "    predictions['Classes'] = predictions['Classes']\n",
    "\n",
    "    metrics = compute_metrics(benchmark=benchmark, predictions=predictions, limit=410, is_qald_gt=is_qald_gt, eval='full')\n",
    "\n",
    "    scores = metrics['macro']['named']\n",
    "    prec, recall, f1 = scores['precision'], scores['recall'], scores['f1']\n",
    "    print(prec, recall, f1)\n",
    "    return prec, recall, f1\n",
    "\n",
    "\n",
    "def evaluate(eval_model, x_eval, y_eval, m_labels_eval, ques_eval, loss_fn, threshold=0.5):\n",
    "    \"\"\"evaluate a model on validation data\"\"\"\n",
    "    eval_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = eval_model(x_eval, m_labels_eval)\n",
    "        loss = loss_fn(val_pred, y_eval)\n",
    "        val_pred_ = val_pred > threshold\n",
    "        print(\"val loss\", loss)\n",
    "        prec, recall, f1 = get_qald_metrics(val_pred_, y_eval, m_labels_eval, ques_eval)\n",
    "#         prec, recall, f1, _ = precision_recall_fscore_support(y_eval, val_pred_, average='macro')\n",
    "        print(\"f1 is {} w/ threshold {} \".format(f1, threshold))\n",
    "#     return loss, f1, val_pred\n",
    "\n",
    "    \n",
    "    return loss, f1, val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss tensor(0.0571)\n",
      "0.4792 0.5417 0.5085\n",
      "f1 is 0.5085 w/ threshold 0.5 \n"
     ]
    }
   ],
   "source": [
    "model = pick_model(args.model_name, args.alpha)\n",
    "loss_fn = nn.BCELoss()\n",
    "loss, f1, val_pred = evaluate(model, x_val, y_val, m_labels_val, ques_val, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5 0.5652 0.5306\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5111 0.5778 0.5424\n",
      "0.5227 0.5909 0.5547\n",
      "0.5227 0.5909 0.5547\n",
      "0.5227 0.5909 0.5547\n",
      "0.5227 0.5909 0.5547\n",
      "0.5227 0.5909 0.5547\n",
      "0.5349 0.6047 0.5676\n",
      "0.5349 0.6047 0.5676\n",
      "0.5349 0.6047 0.5676\n",
      "0.5349 0.6047 0.5676\n",
      "0.5349 0.6047 0.5676\n",
      "0.5349 0.6047 0.5676\n",
      "0.5349 0.6047 0.5676\n",
      "0.5349 0.6047 0.5676\n",
      "0.5476 0.619 0.5811\n",
      "0.5476 0.619 0.5811\n",
      "0.5476 0.619 0.5811\n",
      "0.5476 0.619 0.5811\n",
      "0.5476 0.619 0.5811\n",
      "0.575 0.65 0.6102\n",
      "0.575 0.65 0.6102\n",
      "0.575 0.65 0.6102\n",
      "0.575 0.65 0.6102\n",
      "0.575 0.65 0.6102\n",
      "0.575 0.65 0.6102\n",
      "0.575 0.65 0.6102\n",
      "0.6154 0.6923 0.6516\n",
      "0.6154 0.6923 0.6516\n",
      "0.6154 0.6923 0.6516\n",
      "0.6154 0.6923 0.6516\n",
      "0.6053 0.6842 0.6423\n",
      "0.6053 0.6842 0.6423\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "0.0 0.0 0.0\n",
      "Val -- After tuning, the best f1 is 0.6516 w/ threshold 0.9987878787878788\n"
     ]
    }
   ],
   "source": [
    "best_pred = val_pred\n",
    "best_val_f1, best_val_loss = 0, 1000\n",
    "best_tuned_threshold = 0.5\n",
    "best_tuned_f1 = best_val_f1\n",
    "for threshold_ in np.linspace(0.99, 1.0, num=100):\n",
    "    y_val_preds = best_pred >= threshold_\n",
    "    prec, recall, f1 = get_qald_metrics(y_val_preds, y_val, m_labels_val, ques_val)\n",
    "    if f1 > best_tuned_f1:\n",
    "        best_tuned_threshold = threshold_\n",
    "        best_tuned_f1 = f1\n",
    "print(\"Val -- After tuning, the best f1 is {} w/ threshold {}\".format(best_tuned_f1, best_tuned_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss tensor(0.0524)\n",
      "0.8058 0.7326 0.7674\n",
      "f1 is 0.7674 w/ threshold 0.9994949494949495 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.0524),\n",
       " 0.7674,\n",
       " tensor([[9.9950e-01],\n",
       "         [5.2919e-14],\n",
       "         [2.0628e-04],\n",
       "         ...,\n",
       "         [2.0741e-10],\n",
       "         [5.3063e-20],\n",
       "         [2.0741e-10]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ques_test = df_test.Question\n",
    "\n",
    "evaluate(model, x_test, y_test, m_labels_test, ques_test, loss_fn, threshold=.9994949494949495)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model and evaluate\n",
    "# print(model(x_train, m_labels_train))\n",
    "# best_tuned_threshold = train(model, x_train, y_train, m_labels_train, ques_train, x_val, y_val, m_labels_val, ques_val, args.checkpoint_name, args.num_epoch)\n",
    "# test_pred = test(x_test, y_test, m_labels_test, best_tuned_threshold, args.alpha, args.checkpoint_name, args.model_name)\n",
    "# write_output(df_test, m_labels_test, test_pred, args.output_file_name)\n",
    "\n",
    "# print(args.use_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from el_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_file_path = '../../../data/gt_sparql.csv'\n",
    "prediction_file = 'output/purename_nway_alpha095.csv' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(gold_file_path, prediction_file):\n",
    "    \n",
    "    # gold \n",
    "    benchmark = pd.read_csv(gold_file_path)\n",
    "    benchmark = benchmark.set_index('Question')\n",
    "    benchmark = benchmark.replace(np.nan, '', regex=True)\n",
    "    benchmark['Entities'] = benchmark['Entities'].astype(object)\n",
    "    is_qald_gt = True\n",
    "    \n",
    "    # pred \n",
    "    predictions = pd.read_csv(prediction_file)\n",
    "    predictions = predictions.set_index('Question')\n",
    "    predictions['Entities'] = predictions['Entities']\n",
    "    predictions['Classes'] = predictions['Classes']\n",
    "\n",
    "    metrics = compute_metrics(benchmark=benchmark, predictions=predictions, limit=410, is_qald_gt=is_qald_gt, eval='full')\n",
    "\n",
    "    scores = metrics['macro']['named']\n",
    "    prec, recall, f1 = scores['precision'], scores['recall'], scores['f1']\n",
    "    print(prec, recall, f1)\n",
    "    return prec, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== output/complex_binary_alpha085.csv =====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gold_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d7698bbe9c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprediction_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/*.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=====\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"=====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gold_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import glob, os\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "columns = ['filename', 'alpha', 'precision', 'recall', 'f1']\n",
    "for prediction_file in sorted(glob.glob(\"output/*.csv\")):\n",
    "    print(\"=====\", prediction_file,\"=====\")\n",
    "    prec, rec, f1 = eval(gold_file_path, prediction_file)\n",
    "    filename = prediction_file.split('/')[-1][:-4]\n",
    "    alpha = filename[-2:]\n",
    "    print(filename, alpha, prec, rec, f1)\n",
    "    rows.append([filename, alpha, prec, rec, f1])\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.to_csv('eval_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
