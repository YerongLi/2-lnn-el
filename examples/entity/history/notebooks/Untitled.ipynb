{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qald_metrics(pred_, m_labels_, ques_, mode='val'):\n",
    "    \"\"\"pred_ are 0/1 s after applying a threshold\"\"\"\n",
    "    rows = []\n",
    "    question_rows_map = {}\n",
    "    question_mention_set = set()\n",
    "    for i, pred in enumerate(pred_):\n",
    "        pred = pred.data.tolist()[0]\n",
    "        question = ques_[i]\n",
    "        if question not in question_rows_map:\n",
    "            question_rows_map[ques_[i]] = []\n",
    "        if pred:\n",
    "            men_entity_label = '_'.join(m_labels_[i].split(';')[-1].split())\n",
    "            men_entity_mention = '_'.join(m_labels_[i].split(';')[0].split())\n",
    "            if '-'.join([question, men_entity_mention]) in question_mention_set:\n",
    "                question_rows_map[ques_[i]][-1].add(\n",
    "                    ('http://dbpedia.org/resource/{}'.format(men_entity_label), pred))\n",
    "            else:\n",
    "                question_mention_set.add('-'.join([question, men_entity_mention]))\n",
    "                question_rows_map[ques_val[i]].append(set())\n",
    "                question_rows_map[ques_val[i]][-1].add(\n",
    "                    ('http://dbpedia.org/resource/{}'.format(men_entity_label), pred))\n",
    "    for key, preds_list_mentions in question_rows_map.items():\n",
    "        if len(preds_list_mentions) > 1:\n",
    "            rows.append([key, []])\n",
    "            for preds_set in preds_list_mentions:\n",
    "                sorted_values = sorted(list(preds_set), key=lambda x: x[1], reverse=True)[:5]\n",
    "                rows[-1][1].append(sorted_values)\n",
    "        elif len(preds_list_mentions) == 1:\n",
    "            sorted_values = sorted(list(preds_list_mentions[0]), key=lambda x: x[1], reverse=True)[:5]\n",
    "            rows.append([key, [sorted_values]])\n",
    "        else:\n",
    "            rows.append([key, []])\n",
    "\n",
    "    df_output = pd.DataFrame(rows, columns=['Question', 'Entities'])\n",
    "    df_output['Classes'] = str([])\n",
    "\n",
    "    # generate the csv\n",
    "    if mode == 'test':\n",
    "        df_missing = pd.read_csv(\"data/missing.csv\", header=None)\n",
    "        df_missing.columns = ['Unnamed:0', 'Question', 'Entities', 'Classes']\n",
    "        df_missing = df_missing[['Question', 'Entities', 'Classes']]\n",
    "        df_output = df_output[['Question', 'Entities', 'Classes']]\n",
    "        df_output = pd.concat([df_output, df_missing], ignore_index=True)\n",
    "        print(\"df_output\", df_output.shape)\n",
    "\n",
    "    # gold\n",
    "    benchmark = pd.read_csv('../../../data/gt_sparql.csv')\n",
    "    benchmark = benchmark.set_index('Question')\n",
    "    benchmark = benchmark.replace(np.nan, '', regex=True)\n",
    "    benchmark['Entities'] = benchmark['Entities'].astype(object)\n",
    "    is_qald_gt = True\n",
    "\n",
    "    # pred\n",
    "    predictions = df_output\n",
    "    # print(df_output.shape)\n",
    "    predictions = predictions.set_index('Question')\n",
    "    predictions['Entities'] = predictions['Entities']\n",
    "    predictions['Classes'] = predictions['Classes']\n",
    "\n",
    "    metrics = compute_metrics(benchmark=benchmark, predictions=predictions, limit=410, is_qald_gt=is_qald_gt, eval='full')\n",
    "\n",
    "    scores = metrics['macro']['named']\n",
    "    prec, recall, f1 = scores['precision'], scores['recall'], scores['f1']\n",
    "    return prec, recall, f1, df_output\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
