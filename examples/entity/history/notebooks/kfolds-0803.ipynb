{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import argparse\n",
    "\n",
    "sys.path.append('../../../')\n",
    "from el_evaluation import *\n",
    "from utils import MyBatchSampler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from utils import QuestionSampler\n",
    "import copy\n",
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(103)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"main training script for training lnn entity linking models\")\n",
    "# parser.add_argument(\"--gmt_data\", type=str, default=\"./data/train_sorted.csv\", help=\"train csv\")\n",
    "parser.add_argument(\"--train_data\", type=str, default=\"./data/train_filtered_sorted.csv\", help=\"train csv\")\n",
    "parser.add_argument(\"--test_data\", type=str, default=\"./data/test_sorted.csv\", help=\"test csv\")\n",
    "parser.add_argument(\"--checkpoint_name\", type=str, default=\"checkpoint/best_model.pt\", help=\"checkpoint path\")\n",
    "parser.add_argument(\"--output_file_name\", type=str, default=\"output/purename_nway_alpha09.txt\", help=\"checkpoint path\")\n",
    "parser.add_argument(\"--model_name\", type=str, default=\"purename\", help=\"which model we choose\")\n",
    "# args for dividing the corpus\n",
    "parser.add_argument('--alpha', type=float, default=0.9, help='alpha for LNN')\n",
    "parser.add_argument('--num_epoch', type=int, default=100, help='training epochs for LNN')\n",
    "parser.add_argument(\"--use_binary\", action=\"store_true\", help=\"default is to use binary`, otherwise use stem\")\n",
    "parser.add_argument('--margin', type=float, default=0.15, help='margin for MarginRankingLoss')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument(\"-f\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# from RuleLNN_nway_sigmoid_vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_instances = list(range(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(all_instances):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22462, 8)\n",
      "(17808, 7)\n"
     ]
    }
   ],
   "source": [
    "df_train_val = pd.read_csv(args.train_data)\n",
    "print(df_train_val.shape)\n",
    "df_test = pd.read_csv(args.test_data)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.concat([df_train_val, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['QuestionMention'] = df_data.Question + df_data.Mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How high is the Yokohama Marine Tower?yokohama marine tower\n",
      "In which city does the Chile Route 68 end?chile\n",
      "In which country is the Limerick Lake?limerick lake\n",
      "Which country does the creator of Miffy come from?miffy\n",
      "In which city did John F. Kennedy die?john f. kennedy\n",
      "Who was the successor of John F. Kennedy?john f. kennedy\n",
      "Do Prince Harry and Prince William have the same parents?harry\n",
      "How much did the Lego Movie cost?lego movie\n",
      "Is Michelle Obama the wife of Barack Obama?michelle obama\n",
      "Who wrote the Game of Thrones theme?game of thrones\n",
      "In which city are the headquarters of the United Nations?united nations\n",
      "What country is Sitecore from?sitecore\n",
      "Who was John F. Kennedy's vice president?john f. kennedy\n",
      "Which books by Kerouac were published by Viking Press?viking press\n",
      "With how many countries Iran has borders?iran\n",
      "Is there a video game called Battle Chess?battle chess\n",
      "How tall is Claudia Schiffer?claudia schiffer\n",
      "Who was the wife of U.S. president Lincoln?u.s.\n",
      "Does Breaking Bad have more episodes than Game of Thrones?game of thrones\n",
      "Who is the host of the BBC Wildlife Specials?wildlife specials\n",
      "Does Neymar play for Real Madrid?real madrid\n",
      "Was U.S. president Jackson involved in a war?u.s.\n",
      "Give me all video games published by Mean Hamster Software.mean hamster software\n",
      "In which military conflicts did Lawrence of Arabia participate?lawrence of arabia\n",
      "Who are the writers of the Wall album of Pink Floyd?pink floyd\n",
      "Who is the Formula 1 race driver with the most races?formula 1\n",
      "Who is the host of the BBC Wildlife Specials?bbc\n",
      "How many states are in Mexico?mexico\n",
      "Show me all books in Asimov's Foundation series.asimov 's foundation\n",
      "How tall is Amazon Eve?amazon eve\n"
     ]
    }
   ],
   "source": [
    "only_negative_pairs = []\n",
    "only_one_instance_no_negatives = []\n",
    "for unique_qm_pair in set(df_data.QuestionMention):\n",
    "    df_ = df_data[df_data.QuestionMention == unique_qm_pair]\n",
    "    if df_.Label.sum() == 1 and df_.shape[0] == 1:\n",
    "        print(unique_qm_pair)\n",
    "        only_one_instance_no_negatives.append(unique_qm_pair)\n",
    "    if df_.Label.sum() == 0:\n",
    "        print(unique_qm_pair)\n",
    "        only_negative_pairs.append(unique_qm_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40270, 8)\n",
      "(37376, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df_data.shape)\n",
    "df_filter_negatives = df_data[~df_data.QuestionMention.isin(only_negative_pairs)]\n",
    "print(df_filter_negatives.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37376, 8)\n",
      "(37365, 8)\n"
     ]
    }
   ],
   "source": [
    "print(df_filter_negatives.shape)\n",
    "df_filter_negatives1 = df_filter_negatives[~df_filter_negatives.QuestionMention.isin(only_one_instance_no_negatives)]\n",
    "print(df_filter_negatives1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter_negatives1.to_csv(\"data/data_filtered_sorted.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-477c2b05fc81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(\"data/data_filtered_sorted.csv\")\n",
    "questions_idxes = list(range(len(df_data.Question.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======FOLD-1========\n",
      "(242,)\n",
      "Number of mention-entity pair instances\n",
      "train: torch.Size([27197, 6]) torch.Size([27197, 1]) (27197,) (27197,)\n",
      "test: torch.Size([10168, 6]) torch.Size([10168, 1]) (10168,) (10168,)\n",
      "class distribution\n",
      "y_train sum tensor([276.]) tensor([0.0101])\n",
      "y_test sum tensor([79.]) tensor([0.0078])\n",
      "=======FOLD-2========\n",
      "(242,)\n",
      "Number of mention-entity pair instances\n",
      "train: torch.Size([30594, 6]) torch.Size([30594, 1]) (30594,) (30594,)\n",
      "test: torch.Size([6771, 6]) torch.Size([6771, 1]) (6771,) (6771,)\n",
      "class distribution\n",
      "y_train sum tensor([292.]) tensor([0.0095])\n",
      "y_test sum tensor([63.]) tensor([0.0093])\n",
      "=======FOLD-3========\n",
      "(242,)\n",
      "Number of mention-entity pair instances\n",
      "train: torch.Size([31597, 6]) torch.Size([31597, 1]) (31597,) (31597,)\n",
      "test: torch.Size([5768, 6]) torch.Size([5768, 1]) (5768,) (5768,)\n",
      "class distribution\n",
      "y_train sum tensor([288.]) tensor([0.0091])\n",
      "y_test sum tensor([67.]) tensor([0.0116])\n",
      "=======FOLD-4========\n",
      "(243,)\n",
      "Number of mention-entity pair instances\n",
      "train: torch.Size([30332, 6]) torch.Size([30332, 1]) (30332,) (30332,)\n",
      "test: torch.Size([7033, 6]) torch.Size([7033, 1]) (7033,) (7033,)\n",
      "class distribution\n",
      "y_train sum tensor([280.]) tensor([0.0092])\n",
      "y_test sum tensor([75.]) tensor([0.0107])\n",
      "=======FOLD-5========\n",
      "(243,)\n",
      "Number of mention-entity pair instances\n",
      "train: torch.Size([29740, 6]) torch.Size([29740, 1]) (29740,) (29740,)\n",
      "test: torch.Size([7625, 6]) torch.Size([7625, 1]) (7625,) (7625,)\n",
      "class distribution\n",
      "y_train sum tensor([284.]) tensor([0.0095])\n",
      "y_test sum tensor([71.]) tensor([0.0093])\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "question_list = np.array(df_data.Question.unique())\n",
    "FOLDNUM = 1\n",
    "for train_index, test_index in kf.split(questions_idxes):\n",
    "    print(\"=======FOLD-{}========\".format(FOLDNUM))\n",
    "    FOLDNUM += 1\n",
    "    print(train_index.shape)\n",
    "#     print(question_list[train_index])\n",
    "    train_ques_set = question_list[train_index]\n",
    "    test_ques_test = question_list[test_index]\n",
    "\n",
    "    df_train = df_data[df_data.Question.isin(train_ques_set)]\n",
    "    df_test = df_data[df_data.Question.isin(test_ques_test)]\n",
    "    \n",
    "    # train\n",
    "    features_train = np.array(\n",
    "        [np.fromstring(s[1:-1], dtype=np.float, sep=', ') for s in df_train.Features.values])\n",
    "    x_train = torch.from_numpy(features_train).float()\n",
    "    y_train = torch.from_numpy(df_train.Label.values).float().reshape(-1, 1)\n",
    "    m_labels_train = df_train.Mention_label.values\n",
    "    ques_train = df_train.Question.values\n",
    "\n",
    "    # test\n",
    "    features_test = np.array(\n",
    "        [np.fromstring(s[1:-1], dtype=np.float, sep=', ') for s in df_test.Features.values])\n",
    "    x_test = torch.from_numpy(features_test).float()\n",
    "    y_test = torch.from_numpy(df_test.Label.values).float().reshape(-1, 1)\n",
    "    m_labels_test = df_test.Mention_label.values\n",
    "    ques_test = df_test.Question.values\n",
    "\n",
    "    # aggregate the data into train, val, and test\n",
    "    print(\"Number of mention-entity pair instances\")\n",
    "    train_data = (x_train, y_train, m_labels_train, ques_train)\n",
    "    print(\"train:\", x_train.shape, y_train.shape, m_labels_train.shape, ques_train.shape)\n",
    "    test_data = (x_test, y_test, m_labels_test, ques_test)\n",
    "    print(\"test:\", x_test.shape, y_test.shape, m_labels_test.shape, ques_test.shape)\n",
    "\n",
    "    # check class distribution\n",
    "    print(\"class distribution\")\n",
    "    print(\"y_train sum\", sum(y_train), sum(y_train) / len(y_train))\n",
    "    print(\"y_test sum\", sum(y_test), sum(y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
